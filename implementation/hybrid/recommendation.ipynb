{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pvali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 50, 20\n",
    "import nltk\n",
    "import time\n",
    "start=time.time()\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load your model components\n",
    "vec = load('vec.joblib')\n",
    "vec2 = load('vec2.joblib')\n",
    "pca = load('pca.joblib')\n",
    "lr = load('lr.joblib')\n",
    "comps = load('comps.joblib')\n",
    "df = pd.read_json('df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def update_suggestions_json(user_id, new_suggestions_list):\n",
    "    # Path to the suggestions JSON file\n",
    "    suggestions_file_path = 'suggestions_user.json'\n",
    "    \n",
    "    # Check if the suggestions file already exists\n",
    "    if os.path.isfile(suggestions_file_path):\n",
    "        # Read the existing data\n",
    "        with open(suggestions_file_path, 'r') as file:\n",
    "            suggestions_data = json.load(file)\n",
    "    else:\n",
    "        # Initialize an empty list if the file does not exist\n",
    "        suggestions_data = []\n",
    "    \n",
    "    # Remove any existing suggestions for this user\n",
    "    suggestions_data = [entry for entry in suggestions_data if entry['user_id'] != user_id]\n",
    "    \n",
    "    # Add new suggestions for this user\n",
    "    suggestions_data.extend(new_suggestions_list)\n",
    "    \n",
    "    # Write the updated suggestions back to the JSON file\n",
    "    with open(suggestions_file_path, 'w') as file:\n",
    "        json.dump(suggestions_data, file, indent=4)\n",
    "\n",
    "def give_suggestions(user_id, resume_text):\n",
    "    # Vectorize user's skills and job descriptions\n",
    "    desc = pd.DataFrame(vec.transform([resume_text]).todense())\n",
    "    desc.columns = vec.get_feature_names_out()\n",
    "    skillz = pd.DataFrame(vec2.transform([resume_text]).todense())\n",
    "    skillz.columns = vec2.get_feature_names_out()\n",
    "    mat = pd.concat([skillz, desc], axis=1)\n",
    "    # Transform feature matrix with pca\n",
    "    user_comps = pd.DataFrame(pca.transform(mat))\n",
    "\n",
    "    # Predict cluster for user and print cluster number\n",
    "    cluster = lr.predict(user_comps)[0]\n",
    "    print('CLUSTER NUMBER', cluster, '\\n\\n')\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim = pd.DataFrame(cosine_similarity(user_comps, comps[comps.index == cluster]))\n",
    "\n",
    "    # Get job titles from df to associate cosine similarity scores with jobs\n",
    "    samp_for_cluster = df[df['cluster_no'] == cluster]\n",
    "    cos_sim = cos_sim.T.set_index(samp_for_cluster['title'])\n",
    "    cos_sim.columns = ['score']\n",
    "    \n",
    "    # Print the top ten suggested jobs for the user's cluster\n",
    "    top_cos_sim = cos_sim.sort_values('score', ascending=False)[:10]\n",
    "    print('Top ten suggested for your cluster', '\\n', top_cos_sim, '\\n\\n')\n",
    "    \n",
    "    new_suggestions_list = []\n",
    "    for job_title, score in top_cos_sim.to_dict()['score'].items():\n",
    "        # Find the job_id corresponding to the job_title in samp_for_cluster\n",
    "        job_id = samp_for_cluster[samp_for_cluster['title'] == job_title]['uid'].values[0]\n",
    "        new_suggestions_list.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"job_id\": job_id,\n",
    "            \"suggestions\": job_title,\n",
    "            \"score\": score,\n",
    "            \"feedback\": 0\n",
    "        })\n",
    "    \n",
    "    # Call the function to update the JSON file with new suggestions\n",
    "    update_suggestions_json(user_id, new_suggestions_list)\n",
    "    \n",
    "    return top_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typescript, s, css, express, r, node.js, javascript, html, react\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user_data = pd.read_json(\"../hybrid/user_data.json\")\n",
    "sel_user_id = 1\n",
    "resume_text_row = user_data.loc[user_data['user_id'] == sel_user_id, 'user_data']\n",
    "resume_text = resume_text_row.iloc[0]\n",
    "print(resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER NUMBER 1 \n",
      "\n",
      "\n",
      "Top ten suggested for your cluster \n",
      "                                             score\n",
      "title                                            \n",
      "Sr. Fullstack (Node.js/React) Developer  0.668390\n",
      "Sr. Fullstack (Node.js/React) Developer  0.668390\n",
      "Sr. Fullstack (Node.js/React) Developer  0.668390\n",
      "Software Developer - Front End           0.589798\n",
      "7+ Yrs Sr. Front End Developer           0.547151\n",
      "Senior Backend Developer                 0.428196\n",
      "Cloud Engineer                           0.413607\n",
      "Web Developer, Promotions                0.398589\n",
      "Web Applications Developer               0.369323\n",
      "Front-End Developer (Remote)             0.327625 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cos_sim_result = give_suggestions(sel_user_id, resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feedback(user_id, job_id, feedback):\n",
    "    # Path to the suggestions JSON file\n",
    "    suggestions_file_path = 'suggestions_user.json'\n",
    "    \n",
    "    if not os.path.isfile(suggestions_file_path):\n",
    "        print(\"File not found!\")\n",
    "        return\n",
    "    \n",
    "    with open(suggestions_file_path, 'r') as file:\n",
    "        suggestions_data = json.load(file)\n",
    "    \n",
    "    # Update the feedback for the specific user_id and job_id\n",
    "    for entry in suggestions_data:\n",
    "        if entry['user_id'] == user_id and entry['job_id'] == job_id:\n",
    "            entry['feedback'] = feedback\n",
    "            break\n",
    "    \n",
    "    # Write the updated suggestions back to the JSON file\n",
    "    with open(suggestions_file_path, 'w') as file:\n",
    "        json.dump(suggestions_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_user_feedback(user_id=2, job_id='222d8da33f324a7b836368cdada0a053', feedback=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from typing import List\n",
    "\n",
    "def _single_list_similarity(predicted: list, feature_df: pd.DataFrame, u: int) -> float:\n",
    "    # exception predicted list empty\n",
    "    if not(predicted):\n",
    "        raise Exception('Predicted list is empty, index: {0}'.format(u))\n",
    "\n",
    "    #get features for all recommended items\n",
    "    print(predicted)\n",
    "    feature_df_reset = feature_df.set_index('jobtitle')\n",
    "    print(feature_df_reset)\n",
    "    recs_content = feature_df_reset.concat[predicted]\n",
    "    #recs_content = feature_df.loc[predicted]\n",
    "    recs_content = recs_content.dropna()\n",
    "    recs_content = sp.csr_matrix(recs_content.values)\n",
    "\n",
    "    #calculate similarity scores for all items in list\n",
    "    similarity = cosine_similarity(X=recs_content, dense_output=False)\n",
    "\n",
    "    #get indicies for upper right triangle w/o diagonal\n",
    "    upper_right = np.triu_indices(similarity.shape[0], k=1)\n",
    "\n",
    "    #calculate average similarity score of all recommended items in list\n",
    "    ils_single_user = np.mean(similarity[upper_right])\n",
    "    return ils_single_user\n",
    "\n",
    "def intra_list_similarity(predicted: List[list], feature_df: pd.DataFrame) -> float:\n",
    "    feature_df = feature_df.fillna(0)\n",
    "    Users = range(len(predicted))\n",
    "    print(predicted)\n",
    "    ils = [_single_list_similarity(predicted[u], feature_df, u) for u in Users]\n",
    "    return np.mean(ils)\n",
    "\n",
    "top_10_recommendations=cos_sim_result.sort_values('score', ascending=False)[:10]\n",
    "top_10_list = top_10_recommendations.reset_index().to_records(index=False).tolist()\n",
    "first_elements = [item[0] for item in top_10_list]\n",
    "feature_df = df[['jobtitle','jobdescription']]\n",
    "intra_list_similarity(first_elements, feature_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
