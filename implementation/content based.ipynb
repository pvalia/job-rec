{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "from scipy import spatial\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "c4827ed5e92d47eaa059096e4edea8afcd2a6e06"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link)\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def check_threshold(threshold,ele):\n",
    "        if(ele[0]!=threshold[0][0] and abs(ele[1]-threshold[0][1])<0.03):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def categorize_jobs(self):\n",
    "        nlp=spacy.load('en_core_web_lg')\n",
    "        job_id=self.df2.loc[:,'uniq_id'].tolist()[:self.training_range]\n",
    "        job_titles=self.df2.loc[:,'jobtitle'].tolist()[:self.training_range]\n",
    "        job_descriptions=self.df2.loc[:,'jobdescription'].tolist()[:self.training_range]\n",
    "        final_cat=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        categories=['Network Engineer','Full stack','QA/Test Developer','Enterprise application','DevOps','Mobile Developer','Back End','Database Administrator(DBA)','Front End','Game developer','System Administrator','Data Scientist','Business analyst','Sales professional','Product Manager','Information Security','Software Developer/Java Developer','Web Developer','Cloud Computing']\n",
    "        for category in categories:\n",
    "            final_cat[category]=np.nan\n",
    "        for job_t_d in list(zip(job_id,job_titles,job_descriptions)):\n",
    "            id_job=job_t_d[0]\n",
    "            job_i=job_t_d[1]\n",
    "            job_d=job_t_d[2]\n",
    "            job_title=nlp(job_i.lower())\n",
    "            job_description=nlp(job_d.lower())\n",
    "            match_cat_title=dict()\n",
    "            match_cat_description=dict()\n",
    "            for category in categories:\n",
    "                word=nlp(category.lower())\n",
    "                match_cat_title[category]=job_title.similarity(word)\n",
    "                match_cat_description[category]=job_description.similarity(word)\n",
    "            match_cat_title=sorted(match_cat_title.items(),key=lambda x:x[1],reverse=True)\n",
    "            match_cat_description=sorted(match_cat_description.items(),key=lambda x:x[1],reverse=True)\n",
    "            a=match_cat_title[0]\n",
    "            #print(a)\n",
    "            match_cat_description=list(filter(lambda x: self.check_threshold(match_cat_title,x),match_cat_description))\n",
    "            if(len(match_cat_description)!=0):\n",
    "                print(match_cat_description)\n",
    "                print(id_job)\n",
    "                #b=match_cat_description[0]\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "                match_cat_description.extend([(match_cat_title[0][0],1)])\n",
    "                sum_proportion=sum([x[1] for x in match_cat_description])\n",
    "                for ele in match_cat_description:\n",
    "                    final_cat.loc[id_job,ele[0]]=ele[1]/sum_proportion\n",
    "            else:\n",
    "                print(id_job)\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "        return final_cat\n",
    "    \n",
    "    def clean_skills(self):\n",
    "        extracted_skills=dict()\n",
    "        job_skills=np.asarray(self.df2.loc[:,\"skills\"])\n",
    "        for i in range(self.training_range):\n",
    "            #print(i)\n",
    "            #Method 1: Manual pre-processing\n",
    "            job_id=self.df2.iloc[i,-1]\n",
    "            #Method 2:Using NLTK\n",
    "           # tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "            #print(job_skills[i])\n",
    "            if(pd.isnull(job_skills[i])):\n",
    "                continue\n",
    "            #stopwords_list=stopwords.words(\"english\")\n",
    "            tokens=re.split(\"|\".join([\",\",\" and\",\"/\",\" AND\",\" or\",\" OR\",\";\"]),job_skills[i])\n",
    "            tokens=list(set(tokens))\n",
    "            extracted_skills[job_id]=[]\n",
    "            extracted_skills[job_id].extend(tokens)\n",
    "        return extracted_skills\n",
    "    \n",
    "    \n",
    "    def extract_skills(self,extracted_skills):\n",
    "        df_languages=pd.read_excel('./data/job_profile/languages.xlsx')\n",
    "        df_frameworks=pd.read_csv(\"./data/job_profile/frameworks.csv\")\n",
    "        df_database=pd.read_csv(\"./data/job_profile/database.csv\")\n",
    "        df_os=pd.read_csv(\"./data/job_profile/operating_systems.csv\")\n",
    "        df_plat=pd.read_csv(\"./data/job_profile/platforms.csv\")\n",
    "        frameworks=df_frameworks.iloc[:,1].tolist()\n",
    "        frameworks=[x.lower().strip() for x in frameworks]\n",
    "        #frameworks=[str(x).split(\",\")[0] for x in df_frameworks.iloc[:,1]]\n",
    "        languages=list(df_languages.iloc[:,0])\n",
    "        languages=[x.lower().strip() for x in languages]\n",
    "        #frameworks=[x.lower().strip().split('\\t')[0] for x in frameworks]\n",
    "        databases=df_database.iloc[:,0].tolist()\n",
    "        databases=[x.lower().strip() for x in databases]\n",
    "        op_systems=df_os.iloc[:,0].tolist()\n",
    "        op_systems=[x.lower().strip() for x in op_systems]\n",
    "        platforms=df_plat.iloc[:,1].tolist()\n",
    "        #print(platforms)\n",
    "        platforms=[x.lower().strip() for x in platforms]\n",
    "        #print(frameworks)\n",
    "        new_extracted=dict()\n",
    "        for ele in extracted_skills.keys():\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            #print(extracted_skills[ele])\n",
    "            for skill in extracted_skills[ele]:\n",
    "                skill_base=skill.lower().strip()\n",
    "                #print(skill_base)\n",
    "                if(skill_base in languages):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=skill_base\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+skill_base\n",
    "                elif(skill_base in frameworks):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=skill_base\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+skill_base\n",
    "                elif(skill_base in databases):\n",
    "                    if(final_database==''):\n",
    "                        final_database=skill_base\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+skill_base\n",
    "                elif(skill_base in op_systems):\n",
    "                    if(final_os==''):\n",
    "                        final_os=skill_base\n",
    "                    else:\n",
    "                        final_os=final_os+\",\"+skill_base\n",
    "                elif(skill_base in platforms):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=skill_base\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+skill_base\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=skill_base\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+skill_base\n",
    "            new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        print((list(new_extracted.items()))[:100])\n",
    "        for ele,describe in list(zip(self.df2.loc[:,'uniq_id'],self.df2.loc[:,'jobdescription'].tolist()))[:self.training_range]:\n",
    "            doc=nlp(describe)\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            for ent in doc.ents:\n",
    "                word=ent.text\n",
    "                word=word.lower().strip()\n",
    "                if(word in languages and word not in final_lang and word not in new_extracted[ele][0].split(\",\")):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=word\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+word\n",
    "                elif(word in frameworks and word not in final_frame and word not in new_extracted[ele][1].split(\",\")):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=word\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+word\n",
    "                elif(word in databases and word not in final_database and word not in new_extracted[ele][2].split(\",\")):\n",
    "                    if(final_database==''):\n",
    "                        final_database=word\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+word\n",
    "                elif(word in op_systems and word not in final_os and word not in new_extracted[ele][3].split(\",\")):\n",
    "                    if(final_os==''):\n",
    "                        final_os=word\n",
    "                    else:\n",
    "                        final_os=final_os+\",\"+word\n",
    "                elif(word in platforms and word not in final_plat and word not in new_extracted[ele][4].split(\",\")):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=word\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+word\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=word\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+word\n",
    "            if(final_lang!=''):\n",
    "                new_extracted[ele][0]+=\",\"+final_lang\n",
    "            if(final_frame!=''):\n",
    "                new_extracted[ele][1]+=\",\"+final_frame\n",
    "            if(final_database!=''):\n",
    "                new_extracted[ele][2]+=\",\"+final_database\n",
    "            if(final_os!=''):\n",
    "                new_extracted[ele][3]+=\",\"+final_os\n",
    "            if(final_plat!=''):\n",
    "                new_extracted[ele][4]+=\",\"+final_plat\n",
    "            if(final_others!=''):\n",
    "                new_extracted[ele][5]+=\",\"+final_others\n",
    "            #new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        extracted_skills_df=pd.DataFrame.from_dict(new_extracted,orient='index',columns=['Language','Framework','Database','OS','Platform','Others'])\n",
    "        return extracted_skills_df\n",
    "    \n",
    "    def create_job_profile(self,extracted_skills_df,domain_df):\n",
    "        job_id=extracted_skills_df.index.tolist()\n",
    "        languages_df=pd.DataFrame(index=job_id)\n",
    "        platforms_df=pd.DataFrame(index=job_id)\n",
    "        frameworks_df=pd.DataFrame(index=job_id)\n",
    "        databases_df=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        for job,lang,frame,plat,datab in list(zip(job_id,extracted_skills_df.loc[:,'Language'].tolist(),extracted_skills_df.loc[:,'Framework'].tolist(),extracted_skills_df.loc[:,'Platform'].tolist(),extracted_skills_df.loc[:,'Database'].tolist())):\n",
    "            #Languages\n",
    "            l=lang.split(\",\")\n",
    "            if(lang!=np.nan or lang!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in languages_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        languages_df[ele]=np.nan\n",
    "                    languages_df.loc[job,ele]=1\n",
    "            \n",
    "            #Frameworks\n",
    "            l=frame.split(\",\")\n",
    "            if(frame!=np.nan or frame!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in frameworks_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        frameworks_df[ele]=np.nan\n",
    "                    frameworks_df.loc[job,ele]=1\n",
    "\n",
    "            #Platforms\n",
    "            l=plat.split(\",\")\n",
    "            if(plat!=np.nan or plat!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in platforms_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        platforms_df[ele]=np.nan\n",
    "                    platforms_df.loc[job,ele]=1\n",
    "            \n",
    "            #Databases\n",
    "            l=datab.split(\",\")\n",
    "            if(datab!=np.nan or datab!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in databases_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        databases_df[ele]=np.nan\n",
    "                    databases_df.loc[job,ele]=1\n",
    "        languages_df=languages_df.reindex_axis(sorted(languages_df.columns), axis=1)\n",
    "        frameworks_df=frameworks_df.reindex_axis(sorted(frameworks_df.columns), axis=1)\n",
    "        platforms_df=platforms_df.reindex_axis(sorted(platforms_df.columns), axis=1)\n",
    "        databases_df=databases_df.reindex_axis(sorted(databases_df.columns), axis=1)\n",
    "        domain_df=domain_df.reindex_axis(sorted(domain_df.columns), axis=1)\n",
    "        \n",
    "        languages_df.index.name=frameworks_df.index.name=platforms_df.index.name=databases_df.index.name=domain_df.index.name='uniq_id'\n",
    "        languages_df.to_csv(\"../data/job_profile/languages_job_profile.csv\")\n",
    "        frameworks_df.to_csv(\"../data/job_profile/frameworks_job_profile.csv\")\n",
    "        platforms_df.to_csv(\"../data/job_profile/platforms_job_profile.csv\")\n",
    "        databases_df.to_csv(\"../data/job_profile/databases_job_profile.csv\")\n",
    "        domain_df.to_csv(\"../data/job_profile/domain_job_profile.csv\")\n",
    "        print(languages_df.columns)\n",
    "        \n",
    "    def clean_common_profile(self,df_user,df_job,flag):\n",
    "\n",
    "        if(flag=='Language'):\n",
    "            print(df_job.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('bash')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('bash/shell',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('bash')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('bash/shell',axis=1)\n",
    "\n",
    "        if(flag=='Framework'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('node.js')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('nodejs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('node.js')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('nodejs',axis=1)\n",
    "            \n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('angular')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('angularjs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('angular')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('angularjs',axis=1)\n",
    "            \n",
    "        if(flag=='Platform'):\n",
    "            print(df_user.columns.tolist())\n",
    "        if(flag=='Database'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('sql server')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('microsoft sql server',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('sql server')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('microsoft sql server',axis=1)\n",
    "        return df_user,df_job\n",
    "\n",
    "    def create_common_profile(self,job_profile_path,user_profile_path,output_path,flag=0):\n",
    "        if(flag==0):\n",
    "            \n",
    "            userprofile=pd.read_csv(user_profile_path+\"DevType.csv\",index_col='Respondent')\n",
    "            jobprofile=pd.read_csv(job_profile_path+\"domain_job_profile.csv\",index_col='Unnamed: 0')\n",
    "            print(\"Read from file\")\n",
    "            print(jobprofile.index)\n",
    "            \n",
    "            userprofile.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            jobprofile.drop('uniq_id', axis=1, inplace=True)\n",
    "            jobprofile.index.name='uniq_id'\n",
    "            print(\"index 2in domain\")\n",
    "            print(jobprofile.index)\n",
    "\n",
    "            userprofile.rename(columns={'Product manager':'Product Manager','Back-end developer':'Back End','C-suite executive (CEO, CTO, etc.)':'C-suite executive','Data scientist or machine learning specialist':'Data Scientist','Database administrator':'Database Administrator(DBA)','Mobile developer':'Mobile Developer','Desktop or enterprise applications developer':'Enterprise application','DevOps specialist':'DevOps','Front-end developer':'Front End','Full-stack developer':'Full stack','Marketing or sales professional':'Sales professional','QA or test developer':'QA/Test Developer','System administrator':'System Administrator','Game or graphics developer':'Game developer'},inplace=True)\n",
    "            jobprofile.rename(columns={'Business analyst':'Data or business analyst'},inplace=True)\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            print(\"index in domain\")\n",
    "            print(jobprofile.index)\n",
    "\n",
    "            a=list(set(userprofile.columns)-set(jobprofile.columns))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    jobprofile[i]=0\n",
    "            b=list(set(jobprofile.columns)-set(userprofile.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    userprofile[i]=0\n",
    "            \n",
    "            userprofile=userprofile[sorted(userprofile.columns.tolist())]\n",
    "            jobprofile=jobprofile[sorted(jobprofile.columns.tolist())]\n",
    "             \n",
    "\n",
    "            print(userprofile.columns==jobprofile.columns)\n",
    "\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            userprofile=userprofile[userprofile.columns.tolist()]\n",
    "            jobprofile=jobprofile[jobprofile.columns.tolist()]\n",
    "            userprofile.to_csv(output_path+\"domain_user_profile.csv\")\n",
    "            jobprofile.to_csv(output_path+\"domain_job_profile.csv\")\n",
    "\n",
    "            #Languages\n",
    "            df_user=pd.read_csv(user_profile_path+\"LanguageWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"languages_job_profile.csv\",index_col=0)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(\"index is\")\n",
    "            print(df_job.index)\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            \n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "            columns_to_add=[]\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            print(df_job.index)        \n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "            #df_user=userprofile.reindex_axis(sorted(df_user.columns), axis=1)\n",
    "            #df_job=jobprofile.reindex_axis(sorted(df_job.columns), axis=1)\n",
    "            print(\"index 2\")\n",
    "            print(df_job.index)\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Language')\n",
    "            print(\"language is\")\n",
    "            print(df_job.index[0])\n",
    "            print(df_job.loc[df_job.index[0],:])\n",
    "            df_user.to_csv(output_path+\"languages_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"languages_profile_job.csv\")\n",
    "\n",
    "            #Frameworks\n",
    "            df_user=pd.read_csv(user_profile_path+\"FrameworkWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"frameworks_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            #userprofile=userprofile.reindex_axis(sorted(userprofile.columns), axis=1)\n",
    "            #jobprofile=jobprofile.reindex_axis(sorted(jobprofile.columns), axis=1)\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Framework')   \n",
    "            df_user.to_csv(output_path+\"frameworks_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"frameworks_profile_job.csv\")\n",
    "\n",
    "            #Platforms\n",
    "            df_user=pd.read_csv(user_profile_path+\"PlatformWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"platforms_job_profile.csv\",index_col=0) \n",
    "            print(df_user.columns)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Platform')        \n",
    "            df_user.to_csv(output_path+\"platforms_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"platforms_profile_job.csv\")\n",
    "\n",
    "            #Databases\n",
    "            df_user=pd.read_csv(user_profile_path+\"DatabaseWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"databases_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Database')        \n",
    "            df_user.to_csv(output_path+\"databases_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"databases_profile_job.csv\")\n",
    "        \n",
    "        \n",
    "    def match_profile(self,input_path,user_id,flag=0):\n",
    "        #Match a given user_id with all jobs in the database\n",
    "        \n",
    "        df=pd.read_csv(input_path+\"domain_user_profile.csv\",index_col='Respondent')\n",
    "        #print(df.columns)\n",
    "        matches=dict()\n",
    "        if(flag==0):\n",
    "            if(user_id in df.index):\n",
    "                userdomain=df.loc[user_id,:]\n",
    "                #print(userdomain)\n",
    "                #If user_id exists, retrieve the user profile from input_path\n",
    "                df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "                userlanguages=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "                userframeworks=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "                userplatforms=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "                userdatabases=df.loc[user_id,:]\n",
    "\n",
    "                userdomain=np.asarray(userdomain.fillna(0))\n",
    "                userlanguages=np.asarray(userlanguages.fillna(0))\n",
    "                userframeworks=np.asarray(userframeworks.fillna(0))\n",
    "                userplatforms=np.asarray(userplatforms.fillna(0))\n",
    "                userdatabases=np.asarray(userdatabases.fillna(0))\n",
    "                #print(userdomain)\n",
    "            else:\n",
    "                print(\"error! user id not in Dataset\")\n",
    "            #If it doesn't,take user profile as input\n",
    "        else:\n",
    "\n",
    "            print(\"New user!Enter details..\")\n",
    "            name=input(\"Enter full name\")\n",
    "            skills=input(\"Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience with\").split(\",\")\n",
    "            domains=''\n",
    "            flag=1\n",
    "            while(1):\n",
    "                print(\"Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\")\n",
    "                for i in df.columns:\n",
    "                    print(i,end=\",\")\n",
    "                domains=input().split(\",\")\n",
    "                for domain in domains:\n",
    "                    if(domain not in df.columns):\n",
    "                        flag=0\n",
    "                        break\n",
    "                if(flag==1):\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter valid domain\")\n",
    "            #domains=list(map(lambda x:x.lower(),domains))\n",
    "            skills=list(map(lambda x:x.lower(),skills))                \n",
    "\n",
    "            userdomain=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for domain in domains:\n",
    "                dictionary[domain]=1.0\n",
    "            userdomain=userdomain.append(dictionary,ignore_index=True)\n",
    "            \n",
    "\n",
    "            df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "            userlanguages=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userlanguages=userlanguages.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "            userframeworks=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userframeworks=userframeworks.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "            userplatforms=pd.DataFrame(columns=df.columns)                \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userplatforms=userplatforms.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "            userdatabases=pd.DataFrame(columns=df.columns)               \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userdatabases=userdatabases.append(dictionary,ignore_index=True)\n",
    "            #print(userdomain)\n",
    "            userdomain=np.asarray(userdomain.iloc[0,:].fillna(0))\n",
    "            userlanguages=np.asarray(userlanguages.iloc[0,:].fillna(0))\n",
    "            userframeworks=np.asarray(userframeworks.iloc[0,:].fillna(0))\n",
    "            userplatforms=np.asarray(userplatforms.iloc[0,:].fillna(0))\n",
    "            userdatabases=np.asarray(userdatabases.iloc[0,:].fillna(0))\n",
    "                \n",
    "        jobdomain=pd.read_csv(input_path+\"domain_job_profile.csv\",index_col='uniq_id')\n",
    "        joblanguages=pd.read_csv(input_path+'languages_profile_job.csv',index_col='uniq_id')\n",
    "        jobframeworks=pd.read_csv(input_path+'frameworks_profile_job.csv',index_col='uniq_id')\n",
    "        jobplatforms=pd.read_csv(input_path+'platforms_profile_job.csv',index_col='uniq_id')\n",
    "        jobdatabases=pd.read_csv(input_path+'databases_profile_job.csv',index_col='uniq_id')\n",
    "        #print(len(jobdomain.index),len(joblanguages.index))\n",
    "        \n",
    "        \n",
    "        for i in jobdomain.index:\n",
    "            #print(i)\n",
    "            domain=jobdomain.loc[i,:].fillna(0)\n",
    "            language=joblanguages.loc[i,:].fillna(0)\n",
    "            framework=jobframeworks.loc[i,:].fillna(0)\n",
    "            platform=jobplatforms.loc[i,:].fillna(0)\n",
    "            database=jobdatabases.loc[i,:].fillna(0)\n",
    "            job_id=str(i)\n",
    "            domain=np.asarray(domain)\n",
    "            language=np.asarray(language)\n",
    "            framework=np.asarray(framework)\n",
    "            platform=np.asarray(platform)\n",
    "            database=np.asarray(database)\n",
    "            #print(len(domain),len(userdomain))\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            matches[job_id]=score\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            #Initializing job profiles for later access\n",
    "            self.job_domain=domain\n",
    "            self.job_language=language\n",
    "            self.job_framework=framework\n",
    "            self.job_platform=platform\n",
    "            self.job_database=database\n",
    "            \n",
    "            self.user_domain=userdomain\n",
    "            self.user_language=userlanguages\n",
    "            self.user_framework=userframeworks\n",
    "            self.user_platform=userplatforms\n",
    "            self.user_database=userdatabases\n",
    "        matches=sorted(matches.items(),key=lambda x:x[1],reverse=True)\n",
    "        \n",
    "        recommendations=matches[:10]\n",
    "        #print(\"recommendations are\")\n",
    "\n",
    "        rows=pd.DataFrame(columns=self.df2.columns)\n",
    "        count=0\n",
    "        for i in recommendations:\n",
    "            row=self.df2[self.df2['uniq_id']==i[0]]\n",
    "            rows = pd.concat([rows, row], ignore_index=True)\n",
    "            count=count+1\n",
    "        return rows\n",
    "            \n",
    "# Create an instance of the job_postings class\n",
    "obj = job_postings(\"../data/dice_com-job_us_sample.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanskills = obj.clean_skills()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/job_profile/languages.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extractskills \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleanskills\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 78\u001b[0m, in \u001b[0;36mjob_postings.extract_skills\u001b[1;34m(self, extracted_skills)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_skills\u001b[39m(\u001b[38;5;28mself\u001b[39m,extracted_skills):\n\u001b[1;32m---> 78\u001b[0m     df_languages\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/job_profile/languages.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     df_frameworks\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/job_profile/frameworks.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m     df_database\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/job_profile/database.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pvali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pvali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\pvali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pvali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/job_profile/languages.xlsx'"
     ]
    }
   ],
   "source": [
    "extractskills = obj.extract_skills(cleanskills)\n",
    "obj.create_job_profile(extractskills, domain_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from file\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='Unnamed: 0', length=22000)\n",
      "index 2in domain\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='uniq_id', length=22000)\n",
      "Index(['Front End', 'DevOps', 'Full stack', 'System Administrator',\n",
      "       'Mobile Developer', 'Designer', 'Enterprise application', 'Student',\n",
      "       'QA/Test Developer', 'Game developer', 'Database Administrator(DBA)',\n",
      "       'Engineering manager', 'Educator or academic researcher',\n",
      "       'Data Scientist', 'Product Manager', 'Data or business analyst',\n",
      "       'Back End', 'Sales professional',\n",
      "       'Embedded applications or devices developer', 'C-suite executive'],\n",
      "      dtype='object')\n",
      "Index(['Back End', 'Data or business analyst', 'Cloud Computing',\n",
      "       'Data Scientist', 'Database Administrator(DBA)', 'DevOps',\n",
      "       'Enterprise application', 'Front End', 'Full stack', 'Game developer',\n",
      "       'Information Security', 'Mobile Developer', 'Network Engineer',\n",
      "       'Product Manager', 'QA/Test Developer', 'Sales professional',\n",
      "       'Software Developer/Java Developer', 'System Administrator',\n",
      "       'Web Developer'],\n",
      "      dtype='object')\n",
      "index in domain\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='uniq_id', length=22000)\n",
      "['Embedded applications or devices developer', 'Student', 'C-suite executive', 'Educator or academic researcher', 'Engineering manager', 'Designer']\n",
      "['Web Developer', 'Cloud Computing', 'Information Security', 'Software Developer/Java Developer', 'Network Engineer']\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "Index(['Back End', 'C-suite executive', 'Cloud Computing', 'Data Scientist',\n",
      "       'Data or business analyst', 'Database Administrator(DBA)', 'Designer',\n",
      "       'DevOps', 'Educator or academic researcher',\n",
      "       'Embedded applications or devices developer', 'Engineering manager',\n",
      "       'Enterprise application', 'Front End', 'Full stack', 'Game developer',\n",
      "       'Information Security', 'Mobile Developer', 'Network Engineer',\n",
      "       'Product Manager', 'QA/Test Developer', 'Sales professional',\n",
      "       'Software Developer/Java Developer', 'Student', 'System Administrator',\n",
      "       'Web Developer'],\n",
      "      dtype='object')\n",
      "Index(['Back End', 'C-suite executive', 'Cloud Computing', 'Data Scientist',\n",
      "       'Data or business analyst', 'Database Administrator(DBA)', 'Designer',\n",
      "       'DevOps', 'Educator or academic researcher',\n",
      "       'Embedded applications or devices developer', 'Engineering manager',\n",
      "       'Enterprise application', 'Front End', 'Full stack', 'Game developer',\n",
      "       'Information Security', 'Mobile Developer', 'Network Engineer',\n",
      "       'Product Manager', 'QA/Test Developer', 'Sales professional',\n",
      "       'Software Developer/Java Developer', 'Student', 'System Administrator',\n",
      "       'Web Developer'],\n",
      "      dtype='object')\n",
      "index is\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='uniq_id', length=22000)\n",
      "Index(['Unnamed: 0', 'PHP', 'R', 'Cobol', 'VB.NET', 'Ruby', 'TypeScript',\n",
      "       'Objective-C', 'Python', 'Groovy', 'Go', 'VBA', 'Assembly', 'Perl',\n",
      "       'CSS', 'Swift', 'JavaScript', 'Julia', 'Bash/Shell', 'Erlang', 'Kotlin',\n",
      "       'SQL', 'Haskell', 'Java', 'Matlab', 'C++', 'Ocaml', 'HTML', 'C#',\n",
      "       'Rust', 'Visual Basic 6', 'C', 'F#', 'Hack', 'Scala', 'Clojure',\n",
      "       'Delphi/Object Pascal', 'CoffeeScript', 'Lua'],\n",
      "      dtype='object')\n",
      "Index(['.net', 'abap', 'abc', 'actionscript', 'ada', 'ajax', 'apex', 'apl',\n",
      "       'applescript', 'arc',\n",
      "       ...\n",
      "       'tom', 'transact-sql', 'typescript', 'vbscript', 'verilog', 'vhdl',\n",
      "       'visual basic .net', 'xen', 'xquery', 'xslt'],\n",
      "      dtype='object', length=139)\n",
      "['bash/shell', 'vba', 'delphi/object pascal', 'swift', 'hack', 'visual basic 6']\n",
      "['mercury', 'ladder logic', 's', 'dart', 'ceylon', 'atlas', 'spss', 'rexx', 'scilab', 'tcl', 'mathematica', 'ada', 'automator', 'powershell', 'elixir', 'idl', 'arc', 'verilog', 'falcon', 'arduino', 'lingo', 'apl', 'ecmascript', 'shell', 'inform', 'pl/sql', 'lisp', 'vhdl', 'e', 'labview', 'postscript', '.net', 'c shell', 'gosu', 'clarion', 'd', 'jscript', 'asp', 'opa', 'smalltalk', 'ruby on rails', 'spark', 'caml', 'avenue', 'dcl', 'clean', 'simulink', 'ecl', 'ec', 'puppet', 'applescript', 'ct', 'logo', 'ml', 'smarty', 'jade', 's-plus', 'vbscript', 'fortress', 'occam', 'bourne shell', 'cfml', 'mantis', 'fortran', 'sas', 'abc', 'io', 'magic', 'abap', 'actionscript', 'awk', 'opencl', 'sed', 'xslt', 'moo', 'lpc', 'tacl', 'ch', 'bro', 'tom', 'coldfusion', 'monkey', 'felix', 'mumps', 'xquery', 'lustre', 'pilot', 'ajax', 'korn shell', 'signal', 'ooc', 'icon', 'sqr', 'forth', 'egl', 'apex', 'bc', 'q', 'transact-sql', 'lotusscript', 'xen', 'simula', 'bash', 'cobra', 'self', 'powerscript', 'informix-4gl']\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='uniq_id', length=22000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n",
      "C:\\Users\\pvali\\AppData\\Local\\Temp\\ipykernel_27972\\829474200.py:395: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_user[i]=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2\n",
      "Index(['418ff92580b270ef4e7c14f0ddfc36b4', '8aec88cba08d53da65ab99cf20f6f9d9',\n",
      "       '46baa1f69ac07779274bcd90b85d9a72', '3941b2f206ae0f900c4fba4ac0b18719',\n",
      "       '45efa1f6bc65acc32bbbb953a1ed13b7', 'e0ac9d926dda5e95162ef05adea7318c',\n",
      "       'e7e326053c586bd94e59f1fd74de4a1b', 'b0dadecf4c3c2beecb9c773ca11ecda4',\n",
      "       '28f5e0c1cc3314813e674f0c32b04d1b', '95c9127e2770172f454f3b83981eaa88',\n",
      "       ...\n",
      "       'ba32786b50e8b4d468cb9d813066fea5', '541b0f16ecd86fdbd7ee2b04523dc65e',\n",
      "       'ee46660dd5318edb27b229f51341fcf8', '4b1726afa64b7c9dc640c7862ae64ecc',\n",
      "       '1acc1a7a845f0b9c233ad42941f0462d', '86e27ce6b7e631e55d69d142c7d43df2',\n",
      "       '4287c7ee3317ccf1edd76e238cf8e584', 'd7512f0181d69f83f96db38cd77a4d08',\n",
      "       'ec375268b494b3bcbed1635d64226112', '9a4e8c27f74af4c0d2f6efbd420a8a91'],\n",
      "      dtype='object', name='uniq_id', length=22000)\n",
      "145 145\n",
      "['.net', 'abap', 'abc', 'actionscript', 'ada', 'ajax', 'apex', 'apl', 'applescript', 'arc', 'arduino', 'asp', 'assembly', 'atlas', 'automator', 'avenue', 'awk', 'bash', 'bash/shell', 'bc', 'bourne shell', 'bro', 'c', 'c shell', 'c#', 'c++', 'caml', 'ceylon', 'cfml', 'ch', 'clarion', 'clean', 'clojure', 'cobol', 'cobra', 'coffeescript', 'coldfusion', 'css', 'ct', 'd', 'dart', 'dcl', 'delphi/object pascal', 'e', 'ec', 'ecl', 'ecmascript', 'egl', 'elixir', 'erlang', 'f#', 'falcon', 'felix', 'forth', 'fortran', 'fortress', 'go', 'gosu', 'groovy', 'hack', 'haskell', 'html', 'icon', 'idl', 'inform', 'informix-4gl', 'io', 'jade', 'java', 'javascript', 'jscript', 'julia', 'korn shell', 'kotlin', 'labview', 'ladder logic', 'lingo', 'lisp', 'logo', 'lotusscript', 'lpc', 'lua', 'lustre', 'magic', 'mantis', 'mathematica', 'matlab', 'mercury', 'ml', 'monkey', 'moo', 'mumps', 'objective-c', 'ocaml', 'occam', 'ooc', 'opa', 'opencl', 'perl', 'php', 'pilot', 'pl/sql', 'postscript', 'powerscript', 'powershell', 'puppet', 'python', 'q', 'r', 'rexx', 'ruby', 'ruby on rails', 'rust', 's', 's-plus', 'sas', 'scala', 'scilab', 'sed', 'self', 'shell', 'signal', 'simula', 'simulink', 'smalltalk', 'smarty', 'spark', 'spss', 'sql', 'sqr', 'swift', 'tacl', 'tcl', 'tom', 'transact-sql', 'typescript', 'vb.net', 'vba', 'vbscript', 'verilog', 'vhdl', 'visual basic 6', 'xen', 'xquery', 'xslt']\n",
      "language is\n",
      "418ff92580b270ef4e7c14f0ddfc36b4\n",
      ".net              NaN\n",
      "abap              NaN\n",
      "abc               NaN\n",
      "actionscript      NaN\n",
      "ada               NaN\n",
      "                 ... \n",
      "vhdl              NaN\n",
      "visual basic 6    0.0\n",
      "xen               NaN\n",
      "xquery            NaN\n",
      "xslt              NaN\n",
      "Name: 418ff92580b270ef4e7c14f0ddfc36b4, Length: 144, dtype: float64\n",
      "Index(['Unnamed: 0', 'Torch/PyTorch', 'Django', 'Cordova', 'Node.js',\n",
      "       '.NET Core', 'Spring', 'Xamarin', 'Angular', 'React', 'Hadoop', 'Spark',\n",
      "       'TensorFlow'],\n",
      "      dtype='object')\n",
      "Index(['agile', 'angular', 'angularjs', 'asp.net mvc', 'aura', 'aurelia',\n",
      "       'bottle', 'cakephp', 'cassandra', 'catalyst', 'cloudera', 'codeigniter',\n",
      "       'cordova', 'couchdb', 'cuba', 'django', 'dojo', 'dropwizard',\n",
      "       'durandal', 'elm', 'ember.js', 'express', 'flask', 'flatiron', 'flex',\n",
      "       'flink', 'google web toolkit', 'grails', 'hadoop', 'halcyon', 'hive',\n",
      "       'hpcc', 'jsf', 'koa', 'laravel', 'lift', 'lithium', 'map reduce',\n",
      "       'mason', 'meteor', 'moustache', 'ninja', 'nitro', 'node.js', 'nodejs',\n",
      "       'pentaho', 'phoenix', 'play', 'polymer', 'pyramid', 'rapidminer',\n",
      "       'react', 'revel', 'riot.js', 'ruby on rails', 'rum', 'simplex',\n",
      "       'sinatra', 'solar', 'spark', 'spring', 'storm', 'struts', 'symfony',\n",
      "       'tapestry', 'tensorflow', 'tornado', 'vaadin', 'vanilla', 'vert.x',\n",
      "       'vue.js', 'web2py', 'wicket', 'xamarin', 'yarn', 'yii', 'zend', 'zope'],\n",
      "      dtype='object')\n",
      "['torch/pytorch', '.net core']\n",
      "['wicket', 'aura', 'map reduce', 'jsf', 'polymer', 'cloudera', 'struts', 'play', 'dojo', 'koa', 'sinatra', 'grails', 'cassandra', 'nodejs', 'elm', 'simplex', 'lift', 'riot.js', 'express', 'ninja', 'pentaho', 'vert.x', 'hpcc', 'moustache', 'tapestry', 'tornado', 'pyramid', 'aurelia', 'catalyst', 'couchdb', 'halcyon', 'solar', 'yii', 'revel', 'hive', 'vaadin', 'flex', 'bottle', 'zope', 'rum', 'phoenix', 'asp.net mvc', 'flink', 'google web toolkit', 'cakephp', 'mason', 'vanilla', 'symfony', 'nitro', 'vue.js', 'laravel', 'ruby on rails', 'zend', 'yarn', 'durandal', 'meteor', 'storm', 'web2py', 'codeigniter', 'flask', 'dropwizard', 'cuba', 'flatiron', 'angularjs', 'agile', 'rapidminer', 'ember.js', 'lithium']\n",
      "80 80\n",
      "['.net core', 'agile', 'angular', 'angularjs', 'asp.net mvc', 'aura', 'aurelia', 'bottle', 'cakephp', 'cassandra', 'catalyst', 'cloudera', 'codeigniter', 'cordova', 'couchdb', 'cuba', 'django', 'dojo', 'dropwizard', 'durandal', 'elm', 'ember.js', 'express', 'flask', 'flatiron', 'flex', 'flink', 'google web toolkit', 'grails', 'hadoop', 'halcyon', 'hive', 'hpcc', 'jsf', 'koa', 'laravel', 'lift', 'lithium', 'map reduce', 'mason', 'meteor', 'moustache', 'ninja', 'nitro', 'node.js', 'nodejs', 'pentaho', 'phoenix', 'play', 'polymer', 'pyramid', 'rapidminer', 'react', 'revel', 'riot.js', 'ruby on rails', 'rum', 'simplex', 'sinatra', 'solar', 'spark', 'spring', 'storm', 'struts', 'symfony', 'tapestry', 'tensorflow', 'torch/pytorch', 'tornado', 'vaadin', 'vanilla', 'vert.x', 'vue.js', 'web2py', 'wicket', 'xamarin', 'yarn', 'yii', 'zend', 'zope']\n",
      "Index(['Unnamed: 0', 'Google Cloud Platform/App Engine', 'Windows Phone',\n",
      "       'Heroku', 'iOS', 'Android', 'Gaming console', 'Serverless',\n",
      "       'Apple Watch or Apple TV', 'Windows Desktop or Server', 'Salesforce',\n",
      "       'Predix', 'Mainframe', 'ESP8266', 'Google Home', 'SharePoint', 'AWS',\n",
      "       'Azure', 'Mac OS', 'WordPress', 'Arduino', 'Linux', 'Firebase',\n",
      "       'Drupal', 'Raspberry Pi', 'Amazon Echo', 'IBM Cloud or Watson'],\n",
      "      dtype='object')\n",
      "Index(['amazon echo', 'android', 'arduino', 'aws', 'azure', 'drupal',\n",
      "       'firebase', 'gaming console', 'heroku', 'ios', 'linux', 'mac os',\n",
      "       'mainframe', 'predix', 'raspberry pi', 'salesforce', 'sharepoint',\n",
      "       'windows phone', 'wordpress'],\n",
      "      dtype='object')\n",
      "['serverless', 'apple watch or apple tv', 'google cloud platform/app engine', 'esp8266', 'ibm cloud or watson', 'google home', 'windows desktop or server']\n",
      "[]\n",
      "26 26\n",
      "['amazon echo', 'android', 'apple watch or apple tv', 'arduino', 'aws', 'azure', 'drupal', 'esp8266', 'firebase', 'gaming console', 'google cloud platform/app engine', 'google home', 'heroku', 'ibm cloud or watson', 'ios', 'linux', 'mac os', 'mainframe', 'predix', 'raspberry pi', 'salesforce', 'serverless', 'sharepoint', 'windows desktop or server', 'windows phone', 'wordpress']\n",
      "Index(['Unnamed: 0', 'MariaDB', 'Amazon RDS/Aurora', 'Amazon Redshift',\n",
      "       'Elasticsearch', 'MongoDB', 'Memcached', 'Redis', 'IBM Db2',\n",
      "       'Google Cloud Storage', 'Amazon DynamoDB', 'Google BigQuery', 'MySQL',\n",
      "       'SQLite', 'Neo4j', 'Cassandra', 'PostgreSQL',\n",
      "       'Microsoft Azure (Tables, CosmosDB, SQL, etc)', 'Apache Hive',\n",
      "       'SQL Server', 'Apache HBase', 'Oracle'],\n",
      "      dtype='object')\n",
      "Index(['aster data', 'filemaker pro', 'firebird', 'greenplum', 'hsqldb',\n",
      "       'ibm db2', 'informix', 'mariadb', 'memsql', 'microsoft access',\n",
      "       'microsoft sql server', 'msql', 'mysql', 'netezza', 'oracle',\n",
      "       'panorama', 'postgresql', 'sap hana', 'sqlite', 'teradata', 'timesten',\n",
      "       'unidata', 'universe', 'vertica'],\n",
      "      dtype='object')\n",
      "['amazon dynamodb', 'memcached', 'google bigquery', 'neo4j', 'google cloud storage', 'apache hbase', 'amazon redshift', 'apache hive', 'amazon rds/aurora', 'mongodb', 'elasticsearch', 'sql server', 'redis', 'microsoft azure (tables, cosmosdb, sql, etc)', 'cassandra']\n",
      "['msql', 'aster data', 'sap hana', 'universe', 'panorama', 'firebird', 'timesten', 'hsqldb', 'memsql', 'filemaker pro', 'unidata', 'microsoft sql server', 'vertica', 'microsoft access', 'greenplum', 'informix', 'teradata', 'netezza']\n",
      "39 39\n",
      "['amazon dynamodb', 'amazon rds/aurora', 'amazon redshift', 'apache hbase', 'apache hive', 'aster data', 'cassandra', 'elasticsearch', 'filemaker pro', 'firebird', 'google bigquery', 'google cloud storage', 'greenplum', 'hsqldb', 'ibm db2', 'informix', 'mariadb', 'memcached', 'memsql', 'microsoft access', 'microsoft azure (tables, cosmosdb, sql, etc)', 'microsoft sql server', 'mongodb', 'msql', 'mysql', 'neo4j', 'netezza', 'oracle', 'panorama', 'postgresql', 'redis', 'sap hana', 'sql server', 'sqlite', 'teradata', 'timesten', 'unidata', 'universe', 'vertica']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obj.create_common_profile(\"../data/job_profile/\", \"../data/user_pre/\", \"../data/\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pvali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# Example of matching profiles\n",
    "rows = obj.match_profile(\"../data/\",3,0)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.to_csv(\"../data/collaborative_filt/recommendations2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
