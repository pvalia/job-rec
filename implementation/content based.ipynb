{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "from scipy import spatial\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c4827ed5e92d47eaa059096e4edea8afcd2a6e06"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link)\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def check_threshold(threshold,ele):\n",
    "        if(ele[0]!=threshold[0][0] and abs(ele[1]-threshold[0][1])<0.03):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def categorize_jobs(self):\n",
    "        #categorize jobs based on job titles/ descriptions\n",
    "        nlp=spacy.load('en_core_web_lg')\n",
    "        job_id=self.df2.loc[:,'uniq_id'].tolist()[:self.training_range]\n",
    "        job_titles=self.df2.loc[:,'jobtitle'].tolist()[:self.training_range]\n",
    "        job_descriptions=self.df2.loc[:,'jobdescription'].tolist()[:self.training_range]\n",
    "        final_cat=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        categories=['Network Engineer','Full stack','QA/Test Developer','Enterprise application','DevOps','Mobile Developer','Back End','Database Administrator(DBA)','Front End','Game developer','System Administrator','Data Scientist','Business analyst','Sales professional','Product Manager','Information Security','Software Developer/Java Developer','Web Developer','Cloud Computing']\n",
    "        for category in categories:\n",
    "            final_cat[category]=np.nan\n",
    "        for job_t_d in list(zip(job_id,job_titles,job_descriptions)):\n",
    "            id_job=job_t_d[0]\n",
    "            job_i=job_t_d[1]\n",
    "            job_d=job_t_d[2]\n",
    "            job_title=nlp(job_i.lower())\n",
    "            job_description=nlp(job_d.lower())\n",
    "            match_cat_title=dict()\n",
    "            match_cat_description=dict()\n",
    "            for category in categories:\n",
    "                word=nlp(category.lower())\n",
    "                match_cat_title[category]=job_title.similarity(word)\n",
    "                match_cat_description[category]=job_description.similarity(word)\n",
    "            match_cat_title=sorted(match_cat_title.items(),key=lambda x:x[1],reverse=True)\n",
    "            match_cat_description=sorted(match_cat_description.items(),key=lambda x:x[1],reverse=True)\n",
    "            a=match_cat_title[0]\n",
    "            #print(a)\n",
    "            match_cat_description=list(filter(lambda x: self.check_threshold(match_cat_title,x),match_cat_description))\n",
    "            if(len(match_cat_description)!=0):\n",
    "                print(match_cat_description)\n",
    "                print(id_job)\n",
    "                #b=match_cat_description[0]\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "                match_cat_description.extend([(match_cat_title[0][0],1)])\n",
    "                sum_proportion=sum([x[1] for x in match_cat_description])\n",
    "                for ele in match_cat_description:\n",
    "                    final_cat.loc[id_job,ele[0]]=ele[1]/sum_proportion\n",
    "            else:\n",
    "                print(id_job)\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "        return final_cat\n",
    "    \n",
    "    def clean_skills(self):\n",
    "        # extracts skills from skills column in dataframe\n",
    "        extracted_skills=dict()\n",
    "        job_skills=np.asarray(self.df2.loc[:,\"skills\"])\n",
    "        for i in range(self.training_range):\n",
    "            #print(i)\n",
    "            #Method 1: Manual pre-processing\n",
    "            job_id=self.df2.iloc[i,-1]\n",
    "            #Method 2:Using NLTK\n",
    "           # tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "            #print(job_skills[i])\n",
    "            if(pd.isnull(job_skills[i])):\n",
    "                continue\n",
    "            #stopwords_list=stopwords.words(\"english\")\n",
    "            tokens=re.split(\"|\".join([\",\",\" and\",\"/\",\" AND\",\" or\",\" OR\",\";\"]),job_skills[i])\n",
    "            tokens=list(set(tokens))\n",
    "            extracted_skills[job_id]=[]\n",
    "            extracted_skills[job_id].extend(tokens)\n",
    "        return extracted_skills\n",
    "    \n",
    "    \n",
    "    def extract_skills(self,extracted_skills): #(web scrapping)\n",
    "        # extracts skills from job descriptions\n",
    "        df_languages=pd.read_excel('./data/job_profile/languages.csv')\n",
    "        df_frameworks=pd.read_csv(\"./data/job_profile/frameworks.csv\")\n",
    "        df_database=pd.read_csv(\"./data/job_profile/database.csv\")\n",
    "        df_os=pd.read_csv(\"./data/job_profile/domain.csv\")\n",
    "        df_plat=pd.read_csv(\"./data/job_profile/platforms.csv\")\n",
    "        frameworks=df_frameworks.iloc[:,1].tolist()\n",
    "        frameworks=[x.lower().strip() for x in frameworks]\n",
    "        #frameworks=[str(x).split(\",\")[0] for x in df_frameworks.iloc[:,1]]\n",
    "        languages=list(df_languages.iloc[:,0])\n",
    "        languages=[x.lower().strip() for x in languages]\n",
    "        #frameworks=[x.lower().strip().split('\\t')[0] for x in frameworks]\n",
    "        databases=df_database.iloc[:,0].tolist()\n",
    "        databases=[x.lower().strip() for x in databases]\n",
    "        op_systems=df_os.iloc[:,0].tolist()\n",
    "        op_systems=[x.lower().strip() for x in op_systems]\n",
    "        platforms=df_plat.iloc[:,1].tolist()\n",
    "        #print(platforms)\n",
    "        platforms=[x.lower().strip() for x in platforms]\n",
    "        #print(frameworks)\n",
    "        new_extracted=dict()\n",
    "        for ele in extracted_skills.keys():\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            #print(extracted_skills[ele])\n",
    "            for skill in extracted_skills[ele]:\n",
    "                skill_base=skill.lower().strip()\n",
    "                #print(skill_base)\n",
    "                if(skill_base in languages):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=skill_base\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+skill_base\n",
    "                elif(skill_base in frameworks):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=skill_base\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+skill_base\n",
    "                elif(skill_base in databases):\n",
    "                    if(final_database==''):\n",
    "                        final_database=skill_base\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+skill_base\n",
    "                elif(skill_base in op_systems):\n",
    "                    if(final_os==''):\n",
    "                        final_os=skill_base\n",
    "                    else:\n",
    "                        final_os=final_os+\",\"+skill_base\n",
    "                elif(skill_base in platforms):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=skill_base\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+skill_base\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=skill_base\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+skill_base\n",
    "            new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        print((list(new_extracted.items()))[:100])\n",
    "        for ele,describe in list(zip(self.df2.loc[:,'uniq_id'],self.df2.loc[:,'jobdescription'].tolist()))[:self.training_range]:\n",
    "            doc=nlp(describe)\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            for ent in doc.ents:\n",
    "                word=ent.text\n",
    "                word=word.lower().strip()\n",
    "                if(word in languages and word not in final_lang and word not in new_extracted[ele][0].split(\",\")):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=word\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+word\n",
    "                elif(word in frameworks and word not in final_frame and word not in new_extracted[ele][1].split(\",\")):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=word\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+word\n",
    "                elif(word in databases and word not in final_database and word not in new_extracted[ele][2].split(\",\")):\n",
    "                    if(final_database==''):\n",
    "                        final_database=word\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+word\n",
    "                elif(word in op_systems and word not in final_os and word not in new_extracted[ele][3].split(\",\")):\n",
    "                    if(final_os==''):\n",
    "                        final_os=word\n",
    "                    else:\n",
    "                        final_os=final_os+\",\"+word\n",
    "                elif(word in platforms and word not in final_plat and word not in new_extracted[ele][4].split(\",\")):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=word\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+word\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=word\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+word\n",
    "            if(final_lang!=''):\n",
    "                new_extracted[ele][0]+=\",\"+final_lang\n",
    "            if(final_frame!=''):\n",
    "                new_extracted[ele][1]+=\",\"+final_frame\n",
    "            if(final_database!=''):\n",
    "                new_extracted[ele][2]+=\",\"+final_database\n",
    "            if(final_os!=''):\n",
    "                new_extracted[ele][3]+=\",\"+final_os\n",
    "            if(final_plat!=''):\n",
    "                new_extracted[ele][4]+=\",\"+final_plat\n",
    "            if(final_others!=''):\n",
    "                new_extracted[ele][5]+=\",\"+final_others\n",
    "            #new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        extracted_skills_df=pd.DataFrame.from_dict(new_extracted,orient='index',columns=['Language','Framework','Database','OS','Platform','Others'])\n",
    "        return extracted_skills_df\n",
    "    \n",
    "    def create_job_profile(self,extracted_skills_df,domain_df): #(web scrapping)\n",
    "        #A method that creates job profiles based on extracted skills and domain information. Saves the created job profiles as CSV files.\n",
    "        job_id=extracted_skills_df.index.tolist()\n",
    "        languages_df=pd.DataFrame(index=job_id)\n",
    "        platforms_df=pd.DataFrame(index=job_id)\n",
    "        frameworks_df=pd.DataFrame(index=job_id)\n",
    "        databases_df=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        for job,lang,frame,plat,datab in list(zip(job_id,extracted_skills_df.loc[:,'Language'].tolist(),extracted_skills_df.loc[:,'Framework'].tolist(),extracted_skills_df.loc[:,'Platform'].tolist(),extracted_skills_df.loc[:,'Database'].tolist())):\n",
    "            #Languages\n",
    "            l=lang.split(\",\")\n",
    "            if(lang!=np.nan or lang!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in languages_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        languages_df[ele]=np.nan\n",
    "                    languages_df.loc[job,ele]=1\n",
    "            \n",
    "            #Frameworks\n",
    "            l=frame.split(\",\")\n",
    "            if(frame!=np.nan or frame!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in frameworks_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        frameworks_df[ele]=np.nan\n",
    "                    frameworks_df.loc[job,ele]=1\n",
    "\n",
    "            #Platforms\n",
    "            l=plat.split(\",\")\n",
    "            if(plat!=np.nan or plat!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in platforms_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        platforms_df[ele]=np.nan\n",
    "                    platforms_df.loc[job,ele]=1\n",
    "            \n",
    "            #Databases\n",
    "            l=datab.split(\",\")\n",
    "            if(datab!=np.nan or datab!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in databases_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        databases_df[ele]=np.nan\n",
    "                    databases_df.loc[job,ele]=1\n",
    "        languages_df=languages_df.reindex_axis(sorted(languages_df.columns), axis=1)\n",
    "        frameworks_df=frameworks_df.reindex_axis(sorted(frameworks_df.columns), axis=1)\n",
    "        platforms_df=platforms_df.reindex_axis(sorted(platforms_df.columns), axis=1)\n",
    "        databases_df=databases_df.reindex_axis(sorted(databases_df.columns), axis=1)\n",
    "        domain_df=domain_df.reindex_axis(sorted(domain_df.columns), axis=1)\n",
    "        \n",
    "        languages_df.index.name=frameworks_df.index.name=platforms_df.index.name=databases_df.index.name=domain_df.index.name='uniq_id'\n",
    "        languages_df.to_csv(\"../data/job_profile/languages_job_profile.csv\")\n",
    "        frameworks_df.to_csv(\"../data/job_profile/frameworks_job_profile.csv\")\n",
    "        platforms_df.to_csv(\"../data/job_profile/platforms_job_profile.csv\")\n",
    "        databases_df.to_csv(\"../data/job_profile/databases_job_profile.csv\")\n",
    "        domain_df.to_csv(\"../data/job_profile/domain_job_profile.csv\")\n",
    "        print(languages_df.columns)\n",
    "        \n",
    "    def clean_common_profile(self,df_user,df_job,flag): #(web scrapping)\n",
    "        #A method that performs specific column name cleaning for common profiles (e.g., languages, frameworks, platforms, databases) in user and job profiles\n",
    "        if(flag=='Language'):\n",
    "            print(df_job.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('bash')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('bash/shell',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('bash')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('bash/shell',axis=1)\n",
    "\n",
    "        if(flag=='Framework'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('node.js')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('nodejs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('node.js')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('nodejs',axis=1)\n",
    "            \n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('angular')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('angularjs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('angular')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('angularjs',axis=1)\n",
    "            \n",
    "        if(flag=='Platform'):\n",
    "            print(df_user.columns.tolist())\n",
    "        if(flag=='Database'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.iloc[count, df_user.columns.get_loc('sql server')] = 1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('microsoft sql server',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.iloc[count, df_job.columns.get_loc('sql server')] = 1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('microsoft sql server',axis=1)\n",
    "        return df_user,df_job\n",
    "\n",
    "    def create_common_profile(self,job_profile_path,user_profile_path,output_path,flag=0): #(web scrapping)\n",
    "        #A method that creates common user and job profiles for different skill categories.\n",
    "        #Reads user and job profiles, aligns columns, and saves the cleaned profiles as CSV files.\n",
    "        if(flag==0):\n",
    "            \n",
    "            userprofile=pd.read_csv(user_profile_path+\"DevType.csv\",index_col='Respondent')\n",
    "            jobprofile=pd.read_csv(job_profile_path+\"domain_job_profile.csv\",index_col='Unnamed: 0')\n",
    "            print(\"Read from file\")\n",
    "            print(jobprofile.index)\n",
    "            \n",
    "            userprofile.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            jobprofile.drop('uniq_id', axis=1, inplace=True)\n",
    "            jobprofile.index.name='uniq_id'\n",
    "            print(\"index 2in domain\")\n",
    "            print(jobprofile.index)\n",
    "\n",
    "            userprofile.rename(columns={'Product manager':'Product Manager','Back-end developer':'Back End','C-suite executive (CEO, CTO, etc.)':'C-suite executive','Data scientist or machine learning specialist':'Data Scientist','Database administrator':'Database Administrator(DBA)','Mobile developer':'Mobile Developer','Desktop or enterprise applications developer':'Enterprise application','DevOps specialist':'DevOps','Front-end developer':'Front End','Full-stack developer':'Full stack','Marketing or sales professional':'Sales professional','QA or test developer':'QA/Test Developer','System administrator':'System Administrator','Game or graphics developer':'Game developer'},inplace=True)\n",
    "            jobprofile.rename(columns={'Business analyst':'Data or business analyst'},inplace=True)\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            print(\"index in domain\")\n",
    "            print(jobprofile.index)\n",
    "\n",
    "            a=list(set(userprofile.columns)-set(jobprofile.columns))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    jobprofile[i]=0\n",
    "            b=list(set(jobprofile.columns)-set(userprofile.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    userprofile[i]=0\n",
    "            \n",
    "            userprofile=userprofile[sorted(userprofile.columns.tolist())]\n",
    "            jobprofile=jobprofile[sorted(jobprofile.columns.tolist())]\n",
    "             \n",
    "\n",
    "            print(userprofile.columns==jobprofile.columns)\n",
    "\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            userprofile=userprofile[userprofile.columns.tolist()]\n",
    "            jobprofile=jobprofile[jobprofile.columns.tolist()]\n",
    "            userprofile.to_csv(output_path+\"domain_user_profile.csv\")\n",
    "            jobprofile.to_csv(output_path+\"domain_job_profile.csv\")\n",
    "\n",
    "            #Languages\n",
    "            df_user=pd.read_csv(user_profile_path+\"LanguageWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"languages_job_profile.csv\",index_col=0)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(\"index is\")\n",
    "            print(df_job.index)\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            \n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "            columns_to_add=[]\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            print(df_job.index)        \n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "            #df_user=userprofile.reindex_axis(sorted(df_user.columns), axis=1)\n",
    "            #df_job=jobprofile.reindex_axis(sorted(df_job.columns), axis=1)\n",
    "            print(\"index 2\")\n",
    "            print(df_job.index)\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Language')\n",
    "            print(\"language is\")\n",
    "            print(df_job.index[0])\n",
    "            print(df_job.loc[df_job.index[0],:])\n",
    "            df_user.to_csv(output_path+\"languages_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"languages_profile_job.csv\")\n",
    "\n",
    "            #Frameworks\n",
    "            df_user=pd.read_csv(user_profile_path+\"FrameworkWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"frameworks_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            #userprofile=userprofile.reindex_axis(sorted(userprofile.columns), axis=1)\n",
    "            #jobprofile=jobprofile.reindex_axis(sorted(jobprofile.columns), axis=1)\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Framework')   \n",
    "            df_user.to_csv(output_path+\"frameworks_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"frameworks_profile_job.csv\")\n",
    "\n",
    "            #Platforms\n",
    "            df_user=pd.read_csv(user_profile_path+\"PlatformWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"platforms_job_profile.csv\",index_col=0) \n",
    "            print(df_user.columns)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Platform')        \n",
    "            df_user.to_csv(output_path+\"platforms_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"platforms_profile_job.csv\")\n",
    "\n",
    "            #Databases\n",
    "            df_user=pd.read_csv(user_profile_path+\"DatabaseWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"databases_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Database')        \n",
    "            df_user.to_csv(output_path+\"databases_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"databases_profile_job.csv\")\n",
    "        \n",
    "        \n",
    "    def match_profile(self,input_path,user_id,flag=0): #(content)\n",
    "        #Match a given user_id with all jobs in the database\n",
    "        \n",
    "        df=pd.read_csv(input_path+\"domain_user_profile.csv\",index_col='Respondent')\n",
    "        #print(df.columns)\n",
    "        matches=dict()\n",
    "        if(flag==0):\n",
    "            if(user_id in df.index):\n",
    "                userdomain=df.loc[user_id,:]\n",
    "                #print(userdomain)\n",
    "                #If user_id exists, retrieve the user profile from input_path\n",
    "                df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "                userlanguages=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "                userframeworks=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "                userplatforms=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "                userdatabases=df.loc[user_id,:]\n",
    "\n",
    "                userdomain=np.asarray(userdomain.fillna(0))\n",
    "                userlanguages=np.asarray(userlanguages.fillna(0))\n",
    "                userframeworks=np.asarray(userframeworks.fillna(0))\n",
    "                userplatforms=np.asarray(userplatforms.fillna(0))\n",
    "                userdatabases=np.asarray(userdatabases.fillna(0))\n",
    "                #print(userdomain)\n",
    "            else:\n",
    "                print(\"error! user id not in Dataset\")\n",
    "            #If it doesn't,take user profile as input\n",
    "        else:\n",
    "\n",
    "            print(\"New user!Enter details..\")\n",
    "            name=input(\"Enter full name\")\n",
    "            skills=input(\"Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience with\").split(\",\")\n",
    "            domains=''\n",
    "            flag=1\n",
    "            while(1):\n",
    "                print(\"Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\")\n",
    "                for i in df.columns:\n",
    "                    print(i,end=\",\")\n",
    "                domains=input().split(\",\")\n",
    "                for domain in domains:\n",
    "                    if(domain not in df.columns):\n",
    "                        flag=0\n",
    "                        break\n",
    "                if(flag==1):\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter valid domain\")\n",
    "            #domains=list(map(lambda x:x.lower(),domains))\n",
    "            skills=list(map(lambda x:x.lower(),skills))                \n",
    "\n",
    "            userdomain=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for domain in domains:\n",
    "                dictionary[domain]=1.0\n",
    "            userdomain=userdomain.append(dictionary,ignore_index=True)\n",
    "            \n",
    "\n",
    "            df=pd.read_csv(input_path+\"languages_profile_user.csv\",index_col='Respondent')\n",
    "            userlanguages=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userlanguages=userlanguages.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"frameworks_profile_user.csv\",index_col='Respondent')\n",
    "            userframeworks=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userframeworks=userframeworks.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"platforms_profile_user.csv\",index_col='Respondent')\n",
    "            userplatforms=pd.DataFrame(columns=df.columns)                \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userplatforms=userplatforms.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(input_path+\"databases_profile_user.csv\",index_col='Respondent')\n",
    "            userdatabases=pd.DataFrame(columns=df.columns)               \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userdatabases=userdatabases.append(dictionary,ignore_index=True)\n",
    "            #print(userdomain)\n",
    "            userdomain=np.asarray(userdomain.iloc[0,:].fillna(0))\n",
    "            userlanguages=np.asarray(userlanguages.iloc[0,:].fillna(0))\n",
    "            userframeworks=np.asarray(userframeworks.iloc[0,:].fillna(0))\n",
    "            userplatforms=np.asarray(userplatforms.iloc[0,:].fillna(0))\n",
    "            userdatabases=np.asarray(userdatabases.iloc[0,:].fillna(0))\n",
    "                \n",
    "        jobdomain=pd.read_csv(input_path+\"domain_job_profile.csv\",index_col='uniq_id')\n",
    "        joblanguages=pd.read_csv(input_path+'languages_profile_job.csv',index_col='uniq_id')\n",
    "        jobframeworks=pd.read_csv(input_path+'frameworks_profile_job.csv',index_col='uniq_id')\n",
    "        jobplatforms=pd.read_csv(input_path+'platforms_profile_job.csv',index_col='uniq_id')\n",
    "        jobdatabases=pd.read_csv(input_path+'databases_profile_job.csv',index_col='uniq_id')\n",
    "        #print(len(jobdomain.index),len(joblanguages.index))\n",
    "        \n",
    "        \n",
    "        for i in jobdomain.index:\n",
    "            #print(i)\n",
    "            domain=jobdomain.loc[i,:].fillna(0)\n",
    "            language=joblanguages.loc[i,:].fillna(0)\n",
    "            framework=jobframeworks.loc[i,:].fillna(0)\n",
    "            platform=jobplatforms.loc[i,:].fillna(0)\n",
    "            database=jobdatabases.loc[i,:].fillna(0)\n",
    "            job_id=str(i)\n",
    "            domain=np.asarray(domain)\n",
    "            language=np.asarray(language)\n",
    "            framework=np.asarray(framework)\n",
    "            platform=np.asarray(platform)\n",
    "            database=np.asarray(database)\n",
    "            #print(len(domain),len(userdomain))\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            matches[job_id]=score\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            #Initializing job profiles for later access\n",
    "            self.job_domain=domain\n",
    "            self.job_language=language\n",
    "            self.job_framework=framework\n",
    "            self.job_platform=platform\n",
    "            self.job_database=database\n",
    "            \n",
    "            self.user_domain=userdomain\n",
    "            self.user_language=userlanguages\n",
    "            self.user_framework=userframeworks\n",
    "            self.user_platform=userplatforms\n",
    "            self.user_database=userdatabases\n",
    "        matches=sorted(matches.items(),key=lambda x:x[1],reverse=True)\n",
    "        \n",
    "        recommendations=matches[:10]\n",
    "        #print(\"recommendations are\")\n",
    "\n",
    "        rows=pd.DataFrame(columns=self.df2.columns)\n",
    "        count=0\n",
    "        for i in recommendations:\n",
    "            row=self.df2[self.df2['uniq_id']==i[0]]\n",
    "            rows = pd.concat([rows, row], ignore_index=True)\n",
    "            count=count+1\n",
    "        return rows\n",
    "            \n",
    "# Create an instance of the job_postings class\n",
    "obj = job_postings(\"../data/dice_com-job_us_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat=obj.categorize_jobs()\n",
    "final_cat.to_csv(\"D/data/preprocessed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_skills=obj.clean_skills()\n",
    "extracted_skills_df=obj.extract_skills(extracted_skills)\n",
    "print(extracted_skills_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_df=pd.read_csv(\"D/data/preprocessed_df.csv\")\n",
    "obj.create_job_profile(extracted_skills_df,domain_df)\n",
    "obj.create_common_profile(\"D/data/\",\"Documents/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path represents the location where final job and user profiles\n",
    "df_user=pd.read_csv(\"D/data/survey_results_public.csv\")\n",
    "df_job=pd.read_csv(\"D/data/job_recommend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advertiserurl</th>\n",
       "      <th>company</th>\n",
       "      <th>employmenttype_jobstatus</th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>jobid</th>\n",
       "      <th>joblocation_address</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>postdate</th>\n",
       "      <th>shift</th>\n",
       "      <th>site_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>uniq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.dice.com/jobs/detail/IT-Auditor-WE...</td>\n",
       "      <td>WEX Inc</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior IT AuditorWEX Inc. is a leading and gro...</td>\n",
       "      <td>Dice Id : 10527711</td>\n",
       "      <td>South Portland, ME</td>\n",
       "      <td>IT Auditor</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>www.dice.com</td>\n",
       "      <td>PCI, CISA, CISSP, or CISM, with CIA, IT Audit</td>\n",
       "      <td>daaf56bc42455137549c2d3355675dab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Systems-Suppo...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>Contract W2</td>\n",
       "      <td>Position Details: Position Details:Industry:  ...</td>\n",
       "      <td>Dice Id : 10208346J</td>\n",
       "      <td>Columbia, MO</td>\n",
       "      <td>Systems Support - MQ</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Telecommuting available|Travel not required</td>\n",
       "      <td>www.dice.com</td>\n",
       "      <td>Systems Support</td>\n",
       "      <td>a276e16e80cf010c820b48fdfd9b19b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Desktop-Suppo...</td>\n",
       "      <td>Oakridge Staffing</td>\n",
       "      <td>Full Time, Perm</td>\n",
       "      <td>1 - Senior1-  Junior - This person will just n...</td>\n",
       "      <td>Dice Id : 10124289</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Desktop Support (hedge fund) 2 positions</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 7, Active Directory, Exchange</td>\n",
       "      <td>4565b919bc6ef865f74ca52f0f190571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Desktop-Suppo...</td>\n",
       "      <td>Oakridge Staffing</td>\n",
       "      <td>Full Time, Perm</td>\n",
       "      <td>1 - Senior1-  Junior - This person will just n...</td>\n",
       "      <td>Dice Id : 10124289</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Desktop Support (hedge fund) 2 positions</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 7, Active Directory, Exchange</td>\n",
       "      <td>d3858e790357d9991cc34e0941dd779a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.dice.com/jobs/detail/IT-Help-Desk-...</td>\n",
       "      <td>The FootBridge Companies</td>\n",
       "      <td>Contract Corp-To-Corp, Contract Independent, C...</td>\n",
       "      <td>...</td>\n",
       "      <td>Dice Id : footbrma</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>IT Help Desk Technician (Level 2 Support)</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>www.dice.com</td>\n",
       "      <td>Help Desk, Level 2 Support, Windows, Citrix, L...</td>\n",
       "      <td>008348275ffbd16607a15bf55bae54ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Accounts-Paya...</td>\n",
       "      <td>Pros2Plan</td>\n",
       "      <td>Contract W2, 1 year+poss extn</td>\n",
       "      <td>Pros2Plan, a Spinnaker Company, is now hiring ...</td>\n",
       "      <td>Dice Id : 10513826</td>\n",
       "      <td>Mount Olive, NJ</td>\n",
       "      <td>Accounts Payable (Exp in Procurement &amp; SAP)</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Procurement ,Accounts payable, SAP</td>\n",
       "      <td>404db2ffb28417116d0f08562badc28d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Robert-Half-T...</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Req ID: 145741Job Summary As a member of the S...</td>\n",
       "      <td>Dice Id : 10211279</td>\n",
       "      <td>Cedar Rapids, IA</td>\n",
       "      <td>Robert Half Technology Staffing Support (Temp)</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Development, Manager, Management, Materials, S...</td>\n",
       "      <td>4f086de4a5d6f7d9e17ac149b93e4c48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Robert-Half-T...</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Req ID: 161123Job Summary As a member of the S...</td>\n",
       "      <td>Dice Id : 10211279</td>\n",
       "      <td>Ottawa, ON</td>\n",
       "      <td>Robert Half Technology Staffing Support (Temp)</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Development, Manager, Management, Materials, S...</td>\n",
       "      <td>49fdf4ce7af6c91694ccecb11bb3d01a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Robert-Half-T...</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Req ID: 161121Job Summary As a member of the S...</td>\n",
       "      <td>Dice Id : 10211279</td>\n",
       "      <td>Oakbrook Terrace, IL</td>\n",
       "      <td>Robert Half Technology Staffing Support (Temp)</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Development, Manager, Management, Materials, S...</td>\n",
       "      <td>e59d2fb78ff8f51aee8483a4c65eb7d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.dice.com/jobs/detail/Robert-Half-T...</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Req ID: 156981Job Summary As a member of the S...</td>\n",
       "      <td>Dice Id : 10211279</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Robert Half Technology Staffing Support (Temp)</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Development, Manager, Management, Materials, S...</td>\n",
       "      <td>1a57cadbcd92fecfc4bb907adfefb386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       advertiserurl  \\\n",
       "0  https://www.dice.com/jobs/detail/IT-Auditor-WE...   \n",
       "1  https://www.dice.com/jobs/detail/Systems-Suppo...   \n",
       "2  https://www.dice.com/jobs/detail/Desktop-Suppo...   \n",
       "3  https://www.dice.com/jobs/detail/Desktop-Suppo...   \n",
       "4  https://www.dice.com/jobs/detail/IT-Help-Desk-...   \n",
       "5  https://www.dice.com/jobs/detail/Accounts-Paya...   \n",
       "6  https://www.dice.com/jobs/detail/Robert-Half-T...   \n",
       "7  https://www.dice.com/jobs/detail/Robert-Half-T...   \n",
       "8  https://www.dice.com/jobs/detail/Robert-Half-T...   \n",
       "9  https://www.dice.com/jobs/detail/Robert-Half-T...   \n",
       "\n",
       "                    company  \\\n",
       "0                   WEX Inc   \n",
       "1                 Collabera   \n",
       "2         Oakridge Staffing   \n",
       "3         Oakridge Staffing   \n",
       "4  The FootBridge Companies   \n",
       "5                 Pros2Plan   \n",
       "6               Robert Half   \n",
       "7               Robert Half   \n",
       "8               Robert Half   \n",
       "9               Robert Half   \n",
       "\n",
       "                            employmenttype_jobstatus  \\\n",
       "0                                          Full Time   \n",
       "1                                        Contract W2   \n",
       "2                                    Full Time, Perm   \n",
       "3                                    Full Time, Perm   \n",
       "4  Contract Corp-To-Corp, Contract Independent, C...   \n",
       "5                      Contract W2, 1 year+poss extn   \n",
       "6                                          Full Time   \n",
       "7                                          Full Time   \n",
       "8                                          Full Time   \n",
       "9                                          Full Time   \n",
       "\n",
       "                                      jobdescription                jobid  \\\n",
       "0  Senior IT AuditorWEX Inc. is a leading and gro...   Dice Id : 10527711   \n",
       "1  Position Details: Position Details:Industry:  ...  Dice Id : 10208346J   \n",
       "2  1 - Senior1-  Junior - This person will just n...   Dice Id : 10124289   \n",
       "3  1 - Senior1-  Junior - This person will just n...   Dice Id : 10124289   \n",
       "4                                                ...   Dice Id : footbrma   \n",
       "5  Pros2Plan, a Spinnaker Company, is now hiring ...   Dice Id : 10513826   \n",
       "6  Req ID: 145741Job Summary As a member of the S...   Dice Id : 10211279   \n",
       "7  Req ID: 161123Job Summary As a member of the S...   Dice Id : 10211279   \n",
       "8  Req ID: 161121Job Summary As a member of the S...   Dice Id : 10211279   \n",
       "9  Req ID: 156981Job Summary As a member of the S...   Dice Id : 10211279   \n",
       "\n",
       "    joblocation_address                                        jobtitle  \\\n",
       "0    South Portland, ME                                      IT Auditor   \n",
       "1          Columbia, MO                            Systems Support - MQ   \n",
       "2         Greenwich, CT        Desktop Support (hedge fund) 2 positions   \n",
       "3         Greenwich, CT        Desktop Support (hedge fund) 2 positions   \n",
       "4            Boston, MA       IT Help Desk Technician (Level 2 Support)   \n",
       "5       Mount Olive, NJ     Accounts Payable (Exp in Procurement & SAP)   \n",
       "6      Cedar Rapids, IA  Robert Half Technology Staffing Support (Temp)   \n",
       "7            Ottawa, ON  Robert Half Technology Staffing Support (Temp)   \n",
       "8  Oakbrook Terrace, IL  Robert Half Technology Staffing Support (Temp)   \n",
       "9            Dallas, TX  Robert Half Technology Staffing Support (Temp)   \n",
       "\n",
       "      postdate                                            shift     site_name  \\\n",
       "0  3 weeks ago  Telecommuting not available|Travel not required  www.dice.com   \n",
       "1  2 weeks ago      Telecommuting available|Travel not required  www.dice.com   \n",
       "2  2 weeks ago  Telecommuting not available|Travel not required           NaN   \n",
       "3  2 weeks ago  Telecommuting not available|Travel not required           NaN   \n",
       "4   2 days ago  Telecommuting not available|Travel not required  www.dice.com   \n",
       "5   1 week ago  Telecommuting not available|Travel not required           NaN   \n",
       "6  8 hours ago  Telecommuting not available|Travel not required           NaN   \n",
       "7  7 hours ago  Telecommuting not available|Travel not required           NaN   \n",
       "8  7 hours ago  Telecommuting not available|Travel not required           NaN   \n",
       "9  9 hours ago  Telecommuting not available|Travel not required           NaN   \n",
       "\n",
       "                                              skills  \\\n",
       "0      PCI, CISA, CISSP, or CISM, with CIA, IT Audit   \n",
       "1                                    Systems Support   \n",
       "2              Windows 7, Active Directory, Exchange   \n",
       "3              Windows 7, Active Directory, Exchange   \n",
       "4  Help Desk, Level 2 Support, Windows, Citrix, L...   \n",
       "5                 Procurement ,Accounts payable, SAP   \n",
       "6  Development, Manager, Management, Materials, S...   \n",
       "7  Development, Manager, Management, Materials, S...   \n",
       "8  Development, Manager, Management, Materials, S...   \n",
       "9  Development, Manager, Management, Materials, S...   \n",
       "\n",
       "                            uniq_id  \n",
       "0  daaf56bc42455137549c2d3355675dab  \n",
       "1  a276e16e80cf010c820b48fdfd9b19b6  \n",
       "2  4565b919bc6ef865f74ca52f0f190571  \n",
       "3  d3858e790357d9991cc34e0941dd779a  \n",
       "4  008348275ffbd16607a15bf55bae54ac  \n",
       "5  404db2ffb28417116d0f08562badc28d  \n",
       "6  4f086de4a5d6f7d9e17ac149b93e4c48  \n",
       "7  49fdf4ce7af6c91694ccecb11bb3d01a  \n",
       "8  e59d2fb78ff8f51aee8483a4c65eb7d2  \n",
       "9  1a57cadbcd92fecfc4bb907adfefb386  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pass a third parameter(flag) as 1 in order to get your recommendations!\n",
    "rows=obj.match_profile(\"../data/\",3)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_1000=pd.DataFrame(columns=df_job.columns)\n",
    "for ele in df_user.loc[:,'Respondent'].tolist()[:5000]:\n",
    "    rows=obj.match_profile(\"Documents/data/\",ele)\n",
    "    recommendations_1000=recommendations_1000.append(rows.iloc[0,:],ignore_index=True)\n",
    "\n",
    "recommendations_1000.to_csv(\"D/data/recommend.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.to_csv(\"../data/collaborative_filt/recommendations2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
